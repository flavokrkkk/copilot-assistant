{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRUST ME\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# core\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# general utils\n",
    "import re # regex\n",
    "import json\n",
    "from langdetect import detect # for search query recognition\n",
    "from datasets import Dataset\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed # parallel\n",
    "\n",
    "# Pdf scraping / Rag\n",
    "from langchain.document_loaders import PDFPlumberLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.schema import LLMResult, Generation\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# URL utils\n",
    "import requests # api requests\n",
    "from readability import Document # Url data extraction\n",
    "from bs4 import BeautifulSoup # URL parsing\n",
    "\n",
    "# models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "from transformers import (AlbertTokenizer, \n",
    "                          AlbertForSequenceClassification, \n",
    "                          Trainer, # Only for ALBERT training\n",
    "                          TrainingArguments, # Only for ALBERT training\n",
    "                          AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          pipeline\n",
    "                          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_url(text):\n",
    "    url_pattern = r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)?'\n",
    "    return re.sub(url_pattern, '[URL]', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check [URL] and [URL] for ideas.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_prompt = \"Check http://example.com and http://example.com for ideas.\"\n",
    "replace_url(url_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot with albert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define short class names\n",
    "# Search Query, URL query, User complaints, Human tech help, irrelevant topic\n",
    "class_names = [\"SQ\", \"UQ\", \"CP\", \"SR\", \"IR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {\n",
    "    \"text\": [\n",
    "        \"Как найти хорошую книгу?\", \"Где купить дешевые билеты?\", \"Что посмотреть в выходные?\",  # SQ\n",
    "        \"Смотри [URL], там новости.\", \"На [URL] скидки, проверь.\", \"Это с [URL], что скажешь?\",  # UQ\n",
    "        \"Ваша доставка ужасна!\", \"Почему все так медленно?\", \"Товар сломан, это возмутительно!\",  # CP\n",
    "        \"Помогите настроить роутер.\", \"Свяжите меня с поддержкой.\", \"Как позвонить в техподдержку?\",  # SR\n",
    "        \"Какая погода завтра?\", \"Сколько лет Земле?\", \"Ты любишь кофе?\"  # IR\n",
    "    ],\n",
    "    \"label\": [0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4]  # Class indices\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = Dataset.from_dict(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "albert_model = AlbertForSequenceClassification.from_pretrained(\"./fine_tuned_albert\")\n",
    "albert_tokenizer = AlbertTokenizer.from_pretrained(\"./fine_tuned_albert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model init (in case of train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# albert_tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "# albert_model = AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\", num_labels=len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize dataset\n",
    "def tokenize_function(examples):\n",
    "    return albert_tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 15/15 [00:00<00:00, 243.18 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 15\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results\",\n",
    "#     num_train_epochs=,\n",
    "#     per_device_train_batch_size=4,\n",
    "#     logging_dir=\"./logs\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=albert_model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_dataset,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# albert_model.save_pretrained(\"./fine_tuned_albert\")\n",
    "# albert_tokenizer.save_pretrained(\"./fine_tuned_albert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_query(query):\n",
    "    inputs = albert_tokenizer(query, return_tensors=\"pt\")\n",
    "    outputs = albert_model(**inputs)\n",
    "    predicted_class = torch.argmax(outputs.logits).item()\n",
    "    return class_names[predicted_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('UQ', 'SQ')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_query(\"На [URL] скидки, проверь.\"), classify_query(\"Где купить дешевые билеты?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YandexGPT prompt -> search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_search_query(user_request):\n",
    "    # Create the prompt with the user's request\n",
    "    prompt = f\"Создай поисковой запрос для запроса пользователя: '{user_request}'\"\n",
    "    \n",
    "    # Define the Ollama API endpoint\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    \n",
    "    # Prepare the request payload\n",
    "    data = {\n",
    "        \"model\": \"yandex/YandexGPT-5-Lite-8B-instruct-GGUF:latest\",  # Specify YandexGPT as the model\n",
    "        \"prompt\": prompt       # The instruction for YandexGPT\n",
    "    }\n",
    "    \n",
    "    # Send the request to Ollama API with streaming enabled\n",
    "    response = requests.post(url, json=data, stream=True)\n",
    "    \n",
    "    # Collect the generated search query from the streamed response\n",
    "    search_query = \"\"\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            json_response = json.loads(line)\n",
    "            if \"response\" in json_response:\n",
    "                search_query += json_response[\"response\"]\n",
    "            if json_response.get(\"done\", False):\n",
    "                break\n",
    "    \n",
    "    # Return the cleaned-up search query\n",
    "    return search_query.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'«смартфоны с хорошей камерой»'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_request = \"Хочу телефон с крутой камерой\"\n",
    "try:\n",
    "    search_query = generate_search_query(user_request)\n",
    "except:\n",
    "    search_query = '«смартфоны с хорошей камерой»'\n",
    "search_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_google(query, num_results=5):\n",
    "    \"\"\"\n",
    "    Retrieve search results from Google Custom Search JSON API based on a query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query generated by YandexGPT (e.g., \"best camera phones 2023\").\n",
    "        api_key (str): Your Google API key.\n",
    "        cse_id (str): Your Custom Search Engine ID.\n",
    "        num_results (int): Number of results to return (default: 5, max: 5 per API call).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of URLs from the search results, or an empty list if the request fails.\n",
    "    \"\"\"\n",
    "    # Detect the language of the query for more relevant results\n",
    "    try:\n",
    "        lang = detect(query)\n",
    "    except Exception:\n",
    "        lang = \"en\"  # Default to English if detection fails\n",
    "\n",
    "    # Map detected language to Google's language restriction codes\n",
    "    lang_map = {\"en\": \"lang_en\", \"ru\": \"lang_ru\"}  # Add more languages as needed\n",
    "    lang_code = lang_map.get(lang, \"lang_en\")  # Default to English\n",
    "\n",
    "    # API endpoint\n",
    "    \n",
    "    url = \"https://www.searchapi.io/api/v1/search\"\n",
    "    api_key = \"vRZHJro7avmqfxKi4hB9bhry\" # searchAPI\n",
    "    \n",
    "    # Request parameters\n",
    "    params = {\n",
    "        \"engine\": \"google\",\n",
    "        \"q\": query,          # Search query\n",
    "        \"api_key\": api_key,      # API key\n",
    "        \"num\": num_results+1,  # Number of results\n",
    "        \"lr\": lang_code      # Language restriction\n",
    "    }\n",
    "\n",
    "    # Send the GET request\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        search_json = response.json()\n",
    "        urls = [position['link'] for position in search_json['organic_results']]\n",
    "        return urls\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Search API error: {e}\")\n",
    "        return []  # Return empty list on failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://skillbox.ru/media/design/smartphone-with-a-good-camera/',\n",
       " 'https://hi-tech.mail.ru/review/106257-smartfony-s-khoroshej-kameroj/',\n",
       " 'https://quke.ru/blog/article/top-20-kamerofonov-v-2025-godu?srsltid=AfmBOoqfjCQT2kJ-di5Wa98g_bEjoKmRYLJipWsKdhMp6YgdEnAIH3Yw',\n",
       " 'https://www.eldorado.ru/c/smartfony/tag/horoshaya-kamera/']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# urls = search_with_google(search_query, 5)\n",
    "urls = ['https://skillbox.ru/media/design/smartphone-with-a-good-camera/',\n",
    " 'https://hi-tech.mail.ru/review/106257-smartfony-s-khoroshej-kameroj/',\n",
    " 'https://quke.ru/blog/article/top-20-kamerofonov-v-2025-godu?srsltid=AfmBOoqfjCQT2kJ-di5Wa98g_bEjoKmRYLJipWsKdhMp6YgdEnAIH3Yw',\n",
    " 'https://www.eldorado.ru/c/smartfony/tag/horoshaya-kamera/']\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL information extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_parse(url, timeout=10, max_chars=10000):\n",
    "    \"\"\"\n",
    "    Fetch a web page, extract its main content, and clean the text.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the web page to parse.\n",
    "        timeout (int): Timeout for the request in seconds (default: 10).\n",
    "        max_chars (int): Maximum number of characters to keep (default: 10,000).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the URL and cleaned text, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set a user agent to avoid being blocked\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=timeout)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "        # Extract main content with readability\n",
    "        doc = Document(response.text)\n",
    "        summary = doc.summary()\n",
    "\n",
    "        # Parse and clean the text\n",
    "        soup = BeautifulSoup(summary, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "        text = text[:max_chars]  # Limit text length\n",
    "\n",
    "        return {\"url\": url, \"text\": text}\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_parse_parallel(urls, max_workers=5, timeout=10, max_chars=10000):\n",
    "    \"\"\"\n",
    "    Parse multiple URLs concurrently.\n",
    "\n",
    "    Args:\n",
    "        urls (list): List of URLs to parse.\n",
    "        max_workers (int): Maximum number of concurrent threads (default: 5).\n",
    "        timeout (int): Timeout for each request (default: 10).\n",
    "        max_chars (int): Maximum characters per page (default: 10,000).\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries with URL and cleaned text.\n",
    "    \"\"\"\n",
    "    parsed_contents = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_url = {executor.submit(fetch_and_parse, url, timeout, max_chars): url for url in urls}\n",
    "        for future in as_completed(future_to_url):\n",
    "            content = future.result()\n",
    "            if content:\n",
    "                parsed_contents.append(content)\n",
    "    return parsed_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching https://www.eldorado.ru/c/smartfony/tag/horoshaya-kamera/: 503 Server Error: Service Temporarily Unavailable for url: https://www.eldorado.ru/c/smartfony/tag/horoshaya-kamera/\n"
     ]
    }
   ],
   "source": [
    "parsed_contents = fetch_and_parse_parallel(urls, max_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://skillbox.ru/media/design/smartphone-with-a-good-camera/\n",
      "Text: Изображение: RealmeДисплей: IPS LCD, 6,72\".Основная камера: двойная камера, 108 Мп + 2 Мп.Фронтальна...\n",
      "--------------------------------------------------\n",
      "URL: https://hi-tech.mail.ru/review/106257-smartfony-s-khoroshej-kameroj/\n",
      "Text: Дисплей6,8-дюймовый Dynamic LTPO AMOLED 2X (120 Гц, HDR10+, AOD, до 2600 нит) с разрешением 1440x308...\n",
      "--------------------------------------------------\n",
      "URL: https://quke.ru/blog/article/top-20-kamerofonov-v-2025-godu?srsltid=AfmBOoqfjCQT2kJ-di5Wa98g_bEjoKmRYLJipWsKdhMp6YgdEnAIH3Yw\n",
      "Text: При таком большом количестве вариантов смартфонов на рынке достаточно сложно решить, какой из них лу...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for content in parsed_contents:\n",
    "        print(f\"URL: {content['url']}\")\n",
    "        print(f\"Text: {content['text'][:100]}...\")  # Show first 100 characters\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rag from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YandexGPTLLM(BaseLLM):\n",
    "    def _generate(self, prompts, stop=None):\n",
    "        # Define the Ollama API endpoint\n",
    "        url = \"http://localhost:11434/api/generate\"\n",
    "        \n",
    "        # Prepare the request payload\n",
    "        data = {\n",
    "            \"model\": \"yandex/YandexGPT-5-Lite-8B-instruct-GGUF:latest\",\n",
    "            \"prompt\": prompts[0]  # Take the first prompt (adjust if multiple prompts are needed)\n",
    "        }\n",
    "        \n",
    "        # Send the request with streaming enabled\n",
    "        response = requests.post(url, json=data, stream=True)\n",
    "        \n",
    "        # Collect the generated text from the streamed response\n",
    "        generated_text = \"\"\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                try:\n",
    "                    json_response = json.loads(line)\n",
    "                    if \"response\" in json_response:\n",
    "                        generated_text += json_response[\"response\"]\n",
    "                        print(json_response[\"response\"], end='')\n",
    "                    if json_response.get(\"done\", False):\n",
    "                        break\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Failed to decode JSON: {e}\")\n",
    "        \n",
    "        generation = Generation(text=generated_text)\n",
    "        return LLMResult(generations=[[generation]])\n",
    "\n",
    "    def _llm_type(self):\n",
    "        return \"yandex_gpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    }
   ],
   "source": [
    "loader = PDFPlumberLoader(\"knowledge_base.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = YandexGPTLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "rag_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Xiaomi 14 Ultra и Samsung Galaxy Z Flip 7 лидируют по качеству камеры.Ответ:  Xiaomi 14 Ultra и Samsung Galaxy Z Flip 7 лидируют по качеству камеры.\n"
     ]
    }
   ],
   "source": [
    "query = \"Какой телефон имеет лучшую камеру?\"  # \"Which phone has the best camera?\"\n",
    "result = rag_chain({\"query\": query})\n",
    "print(\"\\nОтвет:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
